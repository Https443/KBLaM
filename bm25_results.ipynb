{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_path: str = r\"C:\\Users\\t-isazawat\\Downloads\\7178_KBLaM_Knowledge_Base_augm_Supplementary Material\\submission files\\knowledge bases\\enron.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"./src\")\n",
    "from kblam.utils.data_utils import load_entities\n",
    "\n",
    "entities = load_entities(kb_path)[0] # TODO: Fix this as this is a hack to account for load_entities being wrongly implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bm25s\n",
    "import numpy as np\n",
    "\n",
    "class Statistics:\n",
    "    def __init__(self):\n",
    "        self.top_1_correct_count = 0\n",
    "        self.top_5_correct_count = 0\n",
    "        self.total_count = 0\n",
    "\n",
    "    def update(self, retrieved_entity_indices, correct_index):\n",
    "        self.total_count += 1\n",
    "        if correct_index in retrieved_entity_indices[:1]:\n",
    "            self.top_1_correct_count += 1\n",
    "        if correct_index in retrieved_entity_indices[:5]:\n",
    "            self.top_5_correct_count += 1\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Top-1 accuracy: {self.top_1_correct_count / self.total_count}, Top-5 accuracy: {self.top_5_correct_count / self.total_count}\"\n",
    "\n",
    "def create_retriever(entities):\n",
    "    corpus = [f\"The {entity['description_type']} of {entity['name']} is {entity['description']}\" for entity in entities]\n",
    "    corpus_tokens = bm25s.tokenize(corpus, stopwords=\"en\")\n",
    "    retriever = bm25s.BM25()\n",
    "    retriever.index(corpus_tokens)\n",
    "    return retriever\n",
    "\n",
    "def experiment_iteration(entities, num_entities, num_queries, stats = None):\n",
    "    if num_entities > len(entities):\n",
    "        raise ValueError(\"num_entities must be less than the number of entities in the dataset\")\n",
    "    if num_queries > num_entities:\n",
    "        raise ValueError(\"num_queries must be less than or equal to num_entities\")\n",
    "    sampled_entities = np.random.choice(entities, num_entities, replace=False)\n",
    "    retriever = create_retriever(sampled_entities)\n",
    "    queries = [entity[\"Q\"] for entity in sampled_entities]\n",
    "\n",
    "    tokenized_queries = bm25s.tokenize(queries, stopwords=\"en\")\n",
    "    retrieved = retriever.retrieve(tokenized_queries, k=5)\n",
    "\n",
    "    if stats is None:\n",
    "        stats = Statistics()\n",
    "    for index, results in enumerate(retrieved[0]):\n",
    "        stats.update(results, index)\n",
    "\n",
    "    return stats\n",
    "\n",
    "def experiment(entities, num_entities, num_iterations, num_queries_per_iteration):\n",
    "    stats = Statistics()\n",
    "    total_experiments = num_iterations * num_queries_per_iteration\n",
    "    print(f\"Running experiment with the following parameters: {num_entities}/{len(entities)} entities, {num_iterations} iterations, {num_queries_per_iteration} queries per iteration, {total_experiments} total queries being run\")\n",
    "    for _ in range(num_iterations):\n",
    "        stats = experiment_iteration(entities, num_entities, num_queries_per_iteration, stats)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with the following parameters: 50/29096 entities, 21 iterations, 50 queries per iteration, 1050 total queries being run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num entities: 50, Top-1 accuracy: 0.9980952380952381, Top-5 accuracy: 0.9990476190476191\n",
      "Running experiment with the following parameters: 100/29096 entities, 21 iterations, 50 queries per iteration, 1050 total queries being run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num entities: 100, Top-1 accuracy: 0.9890476190476191, Top-5 accuracy: 0.9990476190476191\n",
      "Running experiment with the following parameters: 200/29096 entities, 21 iterations, 50 queries per iteration, 1050 total queries being run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num entities: 200, Top-1 accuracy: 0.981904761904762, Top-5 accuracy: 0.9988095238095238\n",
      "Running experiment with the following parameters: 400/29096 entities, 21 iterations, 50 queries per iteration, 1050 total queries being run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num entities: 400, Top-1 accuracy: 0.9678571428571429, Top-5 accuracy: 0.9978571428571429\n",
      "Running experiment with the following parameters: 800/29096 entities, 21 iterations, 50 queries per iteration, 1050 total queries being run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num entities: 800, Top-1 accuracy: 0.9480952380952381, Top-5 accuracy: 0.9956547619047619\n",
      "Running experiment with the following parameters: 1600/29096 entities, 21 iterations, 50 queries per iteration, 1050 total queries being run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num entities: 1600, Top-1 accuracy: 0.8867857142857143, Top-5 accuracy: 0.990625\n",
      "Running experiment with the following parameters: 3200/29096 entities, 21 iterations, 50 queries per iteration, 1050 total queries being run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num entities: 3200, Top-1 accuracy: 0.8625595238095238, Top-5 accuracy: 0.9794047619047619\n",
      "Running experiment with the following parameters: 6400/29096 entities, 21 iterations, 50 queries per iteration, 1050 total queries being run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num entities: 6400, Top-1 accuracy: 0.8009300595238096, Top-5 accuracy: 0.9596205357142857\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(entities):\n",
    "    num_entities = [50, 100, 200, 400, 800, 1600, 3200, 6400]\n",
    "    all_stats = []\n",
    "    for num_entity in num_entities:\n",
    "        stats = experiment(entities, num_entity, int(1000/50) + 1, 50)\n",
    "        all_stats.append(stats)\n",
    "        print(f\"Num entities: {num_entity}, {stats}\")\n",
    "    return all_stats\n",
    "\n",
    "all_stats = run_experiment(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1_acc = []\n",
    "top_5_acc = []\n",
    "for stat in all_stats:\n",
    "    top_1_acc.append(stat.top_1_correct_count / stat.total_count)\n",
    "    top_5_acc.append(stat.top_5_correct_count / stat.total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.998, 0.999], [0.989, 0.999], [0.982, 0.999], [0.968, 0.998], [0.948, 0.996], [0.887, 0.991], [0.863, 0.979], [0.801, 0.96]]\n"
     ]
    }
   ],
   "source": [
    "print(list(list(float('%.3g' % i) for i in el) for el in zip(top_1_acc, top_5_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic:\n",
      "[(50, 0.992), (100, 0.999), (200, 0.994), (400, 0.992), (800, 0.988), (1600, 0.969), (3200, 0.95), (6400, 0.924)]\n",
      "[(50, 1.0), (100, 1.0), (200, 1.0), (400, 1.0), (800, 1.0), (1600, 1.0), (3200, 1.0), (6400, 0.999)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Synthetic:\")\n",
    "num_entities = [50, 100, 200, 400, 800, 1600, 3200, 6400]\n",
    "print(list(zip(num_entities, list(float('%.3g' % i) for i in top_1_acc))))\n",
    "print(list(zip(num_entities, list(float('%.3g' % i) for i in top_5_acc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enron:\n",
      "[(50, 0.998), (100, 0.989), (200, 0.982), (400, 0.968), (800, 0.948), (1600, 0.887), (3200, 0.863), (6400, 0.801)]\n",
      "[(50, 0.999), (100, 0.999), (200, 0.999), (400, 0.998), (800, 0.996), (1600, 0.991), (3200, 0.979), (6400, 0.96)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Enron:\")\n",
    "num_entities = [50, 100, 200, 400, 800, 1600, 3200, 6400]\n",
    "print(list(zip(num_entities, list(float('%.3g' % i) for i in top_1_acc))))\n",
    "print(list(zip(num_entities, list(float('%.3g' % i) for i in top_5_acc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
